# ğŸ›°ï¸ Wi-Fi Certified Product Data Pipeline

A fully automated data pipeline that fetches, processes, and stores **Wi-Fi Certifiedâ„¢ product data** from [Wi-Fi Alliance](https://www.wi-fi.org/) using **GitHub Actions**, **PostgreSQL**, and **Tableau** for visualization.

> **Goal:** Provide up-to-date Wi-Fi certification insights every week through automated data collection and visualization.

---

## ğŸ“Š Overview

This project automates the process of collecting and updating Wi-Fi Certifiedâ„¢ product information weekly.  
It replaces traditional on-premise schedulers (like Airflow) with **GitHub Actions**, enabling cloud-based automation even when the local machine is off.

### ğŸ” Data Flow
Wi-Fi Alliance API â†’ GitHub Actions â†’ PostgreSQL (Neon/Supabase or local) â†’ Tableau (Dashboard)

---

## âš™ï¸ Key Features

- ğŸ•“ **Weekly Scheduled Data Updates** via GitHub Actions  
- â˜ï¸ **No Local Server Needed** â€” runs entirely in the cloud  
- ğŸ§¹ **Automated Data Cleaning & Deduplication**  
- ğŸ—„ï¸ **Storage in PostgreSQL** (local or Neon.tech cloud or Supabase)  
- ğŸ“ˆ **Interactive Tableau Dashboard** for visualization  
- ğŸ’¾ **Historical Data Archiving** (optional: GitHub or Google Drive)

---

## ğŸ§© Tech Stack

| Component | Technology |
|------------|-------------|
| Automation | GitHub Actions |
| Database | PostgreSQL / Neon.tech / Supabase |
| Data Processing | Python (requests, pandas, psycopg2) |
| Visualization | Tableau Public |
| Version Control | Git + GitHub |

---

## ğŸš€ Project Structure
```
wifi_certified_data_pipeline/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚ â””â”€â”€ update_data.yml # GitHub Actions workflow
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ fetch_wifi_data.py # Fetch and clean Wi-Fi data
â”‚ â””â”€â”€ upload_to_postgres.py # Insert data into PostgreSQL
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ (optional) archived_data.csv
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
---

## ğŸ—“ï¸ How It Works

1. **GitHub Actions** triggers every week (e.g., Sunday 00:00 UTC).
2. Python scripts request the latest data from Wi-Fi Alliance API.
3. Data is processed and cleaned with `pandas`.
4. Duplicates from previous weeks are checked and removed.
5. Final dataset is stored in **PostgreSQL** (local or Neon cloud or Supabase).
6. **Tableau** fetches the latest dataset automatically for visualization.

---

## ğŸ”„ Setup (for local testing)

### 1ï¸âƒ£ Create a `.env` file:
```
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
```

### 2ï¸âƒ£ Install dependencies:
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run manually:
```bash
python scripts/fetch_wifi_data.py
python scripts/upload_to_postgres.py
```
