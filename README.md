# ğŸ›°ï¸ Wi-Fi Certified Product Data Pipeline

A fully automated data pipeline that fetches, processes, and stores **Wi-Fi Certifiedâ„¢ product data** from [Wi-Fi Alliance](https://www.wi-fi.org/) using **GitHub Actions**, **PostgreSQL**, and **Streamlit** for visualization.

> **Goal:** Provide up-to-date Wi-Fi certification insights every month through automated data collection and visualization.

---

## ğŸ“Š Overview

This project automates the process of collecting and updating Wi-Fi Certifiedâ„¢ product information weekly.  
It replaces traditional on-premise schedulers (like Airflow) with **GitHub Actions**, enabling cloud-based automation even when the local machine is off.

### ğŸ” Data Flow
Wi-Fi Alliance API â†’ GitHub Actions â†’ PostgreSQL (Neon) â†’ Streamlit (Dashboard)

---

## âš™ï¸ Key Features

- ğŸ•“ **Weekly Scheduled Data Updates** via GitHub Actions
- ğŸ“¦ **Manual Monthly Backups** to GitHub Repository and Google Drive
- â˜ï¸ **No Local Server Needed** â€” runs entirely in the cloud  
- ğŸ§¹ **Automated Data Cleaning & Deduplication**  
- ğŸ—„ï¸ **Storage in PostgreSQL** (local or Neon.tech cloud)  
- ğŸ“ˆ **Interactive Streamlit Dashboard** for visualization  
- ğŸ’¾ **Historical Data Archiving** (GitHub and Google Drive)

---

## ğŸ§© Tech Stack

| Component | Technology |
|------------|-------------|
| Automation | GitHub Actions (Scheduler) |
| Database | PostgreSQL / Neon.tech |
| Data Processing | Python (requests, pandas, psycopg2) |
| Visualization | Streamlit |
| Version Control | Git + GitHub |

---

## ğŸš€ Project Structure
```
wifi_certified_data_pipeline/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚ â””â”€â”€ weekly_wifi_update.yml # GitHub Actions workflow
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ fetch_and_load.py # Fetch and load Wi-Fi data
â”‚ â”œâ”€â”€ gdrive_upload.py # Save last month's Excel data to Google Drive
â”‚ â”œâ”€â”€ dashboard.py # Build visualization for Streamlit
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ YYYY/YYYY-MM.xlsx/csv # Monthly backup files
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
---

## ğŸ—“ï¸ How It Works

1. **GitHub Actions** triggers every week (e.g., Sunday 00:00 UTC) for weekly updates and monthly (1st day 09:00 UTC) for backups.
2. Python script (fetch_and_load.py) requests the latest data from Wi-Fi Alliance API.
3. Data is processed and cleaned with `pandas`.
4. Duplicates from previous weeks are checked and removed.
5. Final dataset is upserted (INSERT/UPDATE) into **PostgreSQL** (Neon cloud).
6. Monthly: A dedicated job exports the previous month's data from PostgreSQL into a CSV and XLSX file and archives them on GitHub and Google Drive.
7. **Streamlit** fetches the latest dataset automatically for visualization.

---

## ğŸ”„ Setup (for local testing)

### 1ï¸âƒ£ Create a `.env` file:
```
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
```

### 2ï¸âƒ£ Install dependencies:
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run manually:
```bash
# weekly update (saved to DB)
python scripts/fetch_and_load.py scheduled_weekly

# monthly backup (export data into CSV/XLSX)
python scripts/fetch_and_load.py monthly_export
```

## â˜ï¸ Deployment via GitHub Actions
The update_data.yml workflow automates the weekly job.
```
name: Update Wi-Fi Certified Data

on:
  schedule:
    - cron: '0 0 * * 0'   # Every Sunday at 00:00 UTC
    - cron: '0 9 1 * *'    # Every 1st day of the month at 09:00 UTC (Monthly Backup)
  workflow_dispatch:

jobs:
  update:  # Weekly update job
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run Weekly Data Update
        run: python scripts/fetch_and_load.py scheduled_weekly
```

## ğŸ“ˆ Streamlit Dashboard

A Streamlit Public dashboard connects directly to your PostgreSQL (Neon) database.
This ensures the dashboard always displays the latest Wi-Fi certification trends.

[Streamlit Dashboard](https://wifi-certified.streamlit.app/) ğŸ‘‰ View Dashboard on Streamlit

## ğŸ’¾ Historical Archiving

Archived data is structured by year and month.
Older data (past months) can be exported and stored in:

```
data/YYYY/YYYY-MM.xlsx/csv within this repo

or Google Drive 
```

## ğŸ§  Future Improvements

- Add visualization for certification frequency trends
- Add a monthly data deletion step to the pipeline to keep the database small.

## ğŸ“œ License

This project is licensed under the MIT License â€” feel free to use and adapt it.

## ğŸ‘©â€ğŸ’» Author

Yuna Kim
